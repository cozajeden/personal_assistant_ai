
### TODO
- [ ] setup openAI, Gork, DeepSeek, Gemini, Llama, etc. free tiers
- [ ] categorize models in DB
- [ ] assign metrics and limits in models
- [ ] functionallity for sessions (In memory session for now)
- [ ] functionallity for tool calls 
- [ ] MCP
- [ ] RAG
- [ ] tracking limits for clouds
- [ ] automate choosing llms
- [x] allow parallel when it is possible (Done by Ollama settings)
- [] Model list
    - [x] Show it
    - [ ] Return filters from API
    - [ ] Model sorting and filtering on backend
    - [ ] Model sorting and filtering on frontend
    
- [x] Chat View (On WebSocket)
- [ ] api with metrics
- [ ] allow conversation branching